# Generated from Grammar1.g4 by ANTLR 4.13.1
from antlr4 import *
from io import StringIO
import sys
if sys.version_info[1] > 5:
    from typing import TextIO
else:
    from typing.io import TextIO


def serializedATN():
    return [
        4,0,21,134,6,-1,2,0,7,0,2,1,7,1,2,2,7,2,2,3,7,3,2,4,7,4,2,5,7,5,
        2,6,7,6,2,7,7,7,2,8,7,8,2,9,7,9,2,10,7,10,2,11,7,11,2,12,7,12,2,
        13,7,13,2,14,7,14,2,15,7,15,2,16,7,16,2,17,7,17,2,18,7,18,2,19,7,
        19,2,20,7,20,1,0,1,0,1,1,1,1,1,1,1,2,1,2,1,3,1,3,1,3,1,3,1,3,1,4,
        1,4,1,4,1,4,1,4,1,5,1,5,1,5,1,5,1,5,1,5,1,6,1,6,1,6,1,6,1,7,1,7,
        1,7,1,8,1,8,1,9,1,9,1,10,1,10,1,11,1,11,1,12,1,12,1,13,1,13,1,14,
        1,14,5,14,88,8,14,10,14,12,14,91,9,14,1,15,4,15,94,8,15,11,15,12,
        15,95,1,16,3,16,99,8,16,1,16,1,16,1,17,1,17,1,17,1,17,1,17,1,18,
        5,18,109,8,18,10,18,12,18,112,9,18,1,18,3,18,115,8,18,1,18,1,18,
        1,19,4,19,120,8,19,11,19,12,19,121,1,19,1,19,1,20,1,20,5,20,128,
        8,20,10,20,12,20,131,9,20,1,20,1,20,0,0,21,1,1,3,2,5,3,7,4,9,5,11,
        6,13,7,15,8,17,9,19,10,21,11,23,12,25,13,27,14,29,15,31,16,33,17,
        35,18,37,19,39,20,41,21,1,0,5,3,0,65,90,95,95,97,122,4,0,48,57,65,
        90,95,95,97,122,1,0,48,57,2,0,9,9,32,32,2,0,10,10,13,13,140,0,1,
        1,0,0,0,0,3,1,0,0,0,0,5,1,0,0,0,0,7,1,0,0,0,0,9,1,0,0,0,0,11,1,0,
        0,0,0,13,1,0,0,0,0,15,1,0,0,0,0,17,1,0,0,0,0,19,1,0,0,0,0,21,1,0,
        0,0,0,23,1,0,0,0,0,25,1,0,0,0,0,27,1,0,0,0,0,29,1,0,0,0,0,31,1,0,
        0,0,0,33,1,0,0,0,0,35,1,0,0,0,0,37,1,0,0,0,0,39,1,0,0,0,0,41,1,0,
        0,0,1,43,1,0,0,0,3,45,1,0,0,0,5,48,1,0,0,0,7,50,1,0,0,0,9,55,1,0,
        0,0,11,60,1,0,0,0,13,66,1,0,0,0,15,70,1,0,0,0,17,73,1,0,0,0,19,75,
        1,0,0,0,21,77,1,0,0,0,23,79,1,0,0,0,25,81,1,0,0,0,27,83,1,0,0,0,
        29,85,1,0,0,0,31,93,1,0,0,0,33,98,1,0,0,0,35,102,1,0,0,0,37,110,
        1,0,0,0,39,119,1,0,0,0,41,125,1,0,0,0,43,44,5,61,0,0,44,2,1,0,0,
        0,45,46,5,105,0,0,46,47,5,102,0,0,47,4,1,0,0,0,48,49,5,58,0,0,49,
        6,1,0,0,0,50,51,5,101,0,0,51,52,5,108,0,0,52,53,5,105,0,0,53,54,
        5,102,0,0,54,8,1,0,0,0,55,56,5,101,0,0,56,57,5,108,0,0,57,58,5,115,
        0,0,58,59,5,101,0,0,59,10,1,0,0,0,60,61,5,119,0,0,61,62,5,104,0,
        0,62,63,5,105,0,0,63,64,5,108,0,0,64,65,5,101,0,0,65,12,1,0,0,0,
        66,67,5,102,0,0,67,68,5,111,0,0,68,69,5,114,0,0,69,14,1,0,0,0,70,
        71,5,105,0,0,71,72,5,110,0,0,72,16,1,0,0,0,73,74,5,42,0,0,74,18,
        1,0,0,0,75,76,5,47,0,0,76,20,1,0,0,0,77,78,5,43,0,0,78,22,1,0,0,
        0,79,80,5,45,0,0,80,24,1,0,0,0,81,82,5,40,0,0,82,26,1,0,0,0,83,84,
        5,41,0,0,84,28,1,0,0,0,85,89,7,0,0,0,86,88,7,1,0,0,87,86,1,0,0,0,
        88,91,1,0,0,0,89,87,1,0,0,0,89,90,1,0,0,0,90,30,1,0,0,0,91,89,1,
        0,0,0,92,94,7,2,0,0,93,92,1,0,0,0,94,95,1,0,0,0,95,93,1,0,0,0,95,
        96,1,0,0,0,96,32,1,0,0,0,97,99,5,13,0,0,98,97,1,0,0,0,98,99,1,0,
        0,0,99,100,1,0,0,0,100,101,5,10,0,0,101,34,1,0,0,0,102,103,5,32,
        0,0,103,104,5,32,0,0,104,105,5,32,0,0,105,106,5,32,0,0,106,36,1,
        0,0,0,107,109,7,3,0,0,108,107,1,0,0,0,109,112,1,0,0,0,110,108,1,
        0,0,0,110,111,1,0,0,0,111,114,1,0,0,0,112,110,1,0,0,0,113,115,5,
        13,0,0,114,113,1,0,0,0,114,115,1,0,0,0,115,116,1,0,0,0,116,117,5,
        10,0,0,117,38,1,0,0,0,118,120,7,3,0,0,119,118,1,0,0,0,120,121,1,
        0,0,0,121,119,1,0,0,0,121,122,1,0,0,0,122,123,1,0,0,0,123,124,6,
        19,0,0,124,40,1,0,0,0,125,129,5,35,0,0,126,128,8,4,0,0,127,126,1,
        0,0,0,128,131,1,0,0,0,129,127,1,0,0,0,129,130,1,0,0,0,130,132,1,
        0,0,0,131,129,1,0,0,0,132,133,6,20,0,0,133,42,1,0,0,0,8,0,89,95,
        98,110,114,121,129,1,6,0,0
    ]

class Grammar1Lexer(Lexer):

    atn = ATNDeserializer().deserialize(serializedATN())

    decisionsToDFA = [ DFA(ds, i) for i, ds in enumerate(atn.decisionToState) ]

    T__0 = 1
    T__1 = 2
    T__2 = 3
    T__3 = 4
    T__4 = 5
    T__5 = 6
    T__6 = 7
    T__7 = 8
    T__8 = 9
    T__9 = 10
    T__10 = 11
    T__11 = 12
    T__12 = 13
    T__13 = 14
    ID = 15
    INT = 16
    NEWLINE = 17
    INDENT = 18
    DEDENT = 19
    WS = 20
    COMMENT = 21

    channelNames = [ u"DEFAULT_TOKEN_CHANNEL", u"HIDDEN" ]

    modeNames = [ "DEFAULT_MODE" ]

    literalNames = [ "<INVALID>",
            "'='", "'if'", "':'", "'elif'", "'else'", "'while'", "'for'", 
            "'in'", "'*'", "'/'", "'+'", "'-'", "'('", "')'", "'    '" ]

    symbolicNames = [ "<INVALID>",
            "ID", "INT", "NEWLINE", "INDENT", "DEDENT", "WS", "COMMENT" ]

    ruleNames = [ "T__0", "T__1", "T__2", "T__3", "T__4", "T__5", "T__6", 
                  "T__7", "T__8", "T__9", "T__10", "T__11", "T__12", "T__13", 
                  "ID", "INT", "NEWLINE", "INDENT", "DEDENT", "WS", "COMMENT" ]

    grammarFileName = "Grammar1.g4"

    def __init__(self, input=None, output:TextIO = sys.stdout):
        super().__init__(input, output)
        self.checkVersion("4.13.1")
        self._interp = LexerATNSimulator(self, self.atn, self.decisionsToDFA, PredictionContextCache())
        self._actions = None
        self._predicates = None


